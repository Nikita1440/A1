{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f1178a",
   "metadata": {},
   "source": [
    "1. Provide an example of the concepts of Prior, Posterior, and Likelihood.\n",
    "2. What role does Bayes&#39; theorem play in the concept learning principle?\n",
    "3. Offer an example of how the Nave Bayes classifier is used in real life.\n",
    "\n",
    "4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about\n",
    "doing it?\n",
    "\n",
    "5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they\n",
    "capable of resolving a wide range of issues?\n",
    "\n",
    "6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the\n",
    "random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the\n",
    "variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98\n",
    "and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered,\n",
    "implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) =\n",
    "0.00001. What are the chances that an alarm would be triggered when an individual is actually an\n",
    "intruder?\n",
    "\n",
    "7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are\n",
    "not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of\n",
    "those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those\n",
    "actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were\n",
    "antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune\n",
    "(random variable D).\n",
    "\n",
    "8. In order to prepare for the test, a student knows that there will be one question in the exam that\n",
    "is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and\n",
    "50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10\n",
    "type B problems, and 6 of 10 type C problems.\n",
    "\n",
    "1. What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "2. Given the student&#39;s solution, what is the likelihood that the problem was of form A?\n",
    "\n",
    "9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant\n",
    "influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into\n",
    "the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for\n",
    "simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If\n",
    "\n",
    "there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the\n",
    "camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "\n",
    "1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "2. On a daily basis, how many fake photographs (photographs taken when there is no\n",
    "customer) and how many missed photographs (photographs taken when there is a customer) are\n",
    "there?\n",
    "\n",
    "3. Explain likelihood that there is a customer if there is a photograph?\n",
    "\n",
    "10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief\n",
    "network to represent the conditional independence assumptions of the Nave Bayes classifier for the\n",
    "match winning prediction problem in Section 6.4.4.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "Sure! Let's consider a scenario where we want to determine the probability of a student passing an exam based on their study hours.\n",
    "\n",
    "Prior: The prior probability represents our initial belief or knowledge about the probability of a student passing the exam before considering any specific information. For example, based on historical data or general assumptions, we might assume that 70% of students pass the exam regardless of their study hours. This 70% is the prior probability.\n",
    "\n",
    "Likelihood: The likelihood is the probability of observing the data or evidence given a specific hypothesis or parameter value. In this case, it is the probability of a student passing the exam given their study hours. Let's say we collect data from previous exams and find that among students who studied for 10 hours, 90% of them passed. This 90% is the likelihood.\n",
    "\n",
    "Posterior: The posterior probability is the updated probability of a hypothesis or parameter value after considering the observed data. It combines the prior probability and the likelihood using Bayes' theorem. Using the prior probability of 70% and the likelihood of 90% for studying 10 hours, we can calculate the posterior probability of a student passing the exam after studying for 10 hours.\n",
    "\n",
    "By updating the prior probability with the likelihood using Bayes' theorem, we obtain a more informed and updated estimate of the probability of a student passing the exam based on their study hours.\n",
    "\n",
    "Note that the example probabilities used in this explanation are for illustrative purposes and may not reflect real-world values. The actual probabilities would depend on the specific context and data available.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2\n",
    "Bayes' theorem plays a fundamental role in the concept learning principle by providing a way to update our beliefs or hypotheses based on new evidence or data. The concept learning principle is the process of inferring or learning concepts from observed examples or data.\n",
    "\n",
    "Bayes' theorem allows us to calculate the posterior probability of a hypothesis or concept given the observed data, by combining the prior probability (our initial belief about the hypothesis) and the likelihood (the probability of observing the data given the hypothesis).\n",
    "\n",
    "In the context of concept learning, Bayes' theorem helps us update our belief in a particular concept or hypothesis based on the evidence provided by observed examples. We start with a prior probability distribution over possible concepts and update it using Bayes' theorem as we observe new examples.\n",
    "\n",
    "By iteratively updating our beliefs based on new evidence, we can refine our understanding of the concept and improve our ability to make predictions or classifications. This process of updating beliefs using Bayes' theorem is known as Bayesian inference and is a key component of many machine learning and artificial intelligence algorithms.\n",
    "\n",
    "In summary, Bayes' theorem is central to the concept learning principle as it allows us to update our beliefs about concepts or hypotheses based on observed data, enabling us to learn and infer new concepts from examples.\n",
    "\n",
    "\n",
    "\n",
    "3\n",
    "\n",
    "\n",
    "\n",
    "One example of how the Naive Bayes classifier is used in real life is in email spam filtering. Email providers employ Naive Bayes classifiers to automatically categorize incoming emails as either spam or legitimate (ham).\n",
    "\n",
    "The Naive Bayes classifier works by learning the probabilities of different features in spam and ham emails and then using these probabilities to classify new, unseen emails. It assumes that the features are independent of each other, which is known as the \"naive\" assumption.\n",
    "\n",
    "In this case, the features can include the presence or absence of certain words, the frequency of certain words, the presence of specific email headers, and other characteristics of the email content. The classifier learns the probabilities of these features based on a labeled dataset of known spam and ham emails.\n",
    "\n",
    "Once the classifier is trained, it can analyze new incoming emails and calculate the probability that each email is spam or ham based on the observed features. It then assigns the email to the category with the higher probability.\n",
    "\n",
    "This approach is effective because spam emails often exhibit specific patterns or characteristics that differ from legitimate emails. By leveraging the probabilities of different features, the Naive Bayes classifier can make accurate predictions about the spam/ham status of incoming emails.\n",
    "\n",
    "Many popular email services, such as Gmail, use Naive Bayes classifiers as part of their spam filtering systems. The classifier continuously learns and adapts based on user feedback and updates to its training dataset, improving its ability to accurately identify and filter spam emails.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4\n",
    "\n",
    "\n",
    "\n",
    "Yes, the Naive Bayes classifier can be used on continuous numeric data. However, it requires an assumption or modeling technique to handle the continuous nature of the data.\n",
    "\n",
    "One common approach is to assume that the continuous features follow a specific probability distribution, such as the Gaussian (Normal) distribution. In this case, the classifier is often referred to as Gaussian Naive Bayes.\n",
    "\n",
    "To use Gaussian Naive Bayes on continuous numeric data, the following steps are typically followed:\n",
    "\n",
    "Preprocess the data: Standardize or normalize the continuous features to ensure they have a similar scale and distribution. This step helps in maintaining the assumptions of the Gaussian distribution.\n",
    "\n",
    "Train the classifier: Calculate the class-specific mean and standard deviation for each continuous feature based on the labeled training data. This involves estimating the parameters of the Gaussian distribution for each class.\n",
    "\n",
    "Calculate likelihoods: For each test instance, calculate the likelihood of observing the feature values given each class's Gaussian distribution. This is done using the probability density function (PDF) of the Gaussian distribution.\n",
    "\n",
    "Calculate prior probabilities: Determine the prior probabilities of each class based on the training data. These represent the probability of each class occurring without considering the feature values.\n",
    "\n",
    "Apply Bayes' theorem: Combine the prior probabilities and likelihoods using Bayes' theorem to calculate the posterior probabilities of each class for the test instance.\n",
    "\n",
    "Make predictions: Assign the test instance to the class with the highest posterior probability.\n",
    "\n",
    "It's important to note that the assumption of feature independence (the \"naive\" assumption) still holds in Gaussian Naive Bayes, even though the features are continuous. This assumption allows for simple and efficient computation of the probabilities.\n",
    "\n",
    "Gaussian Naive Bayes is a popular choice for continuous numeric data classification, especially when the features exhibit approximately Gaussian distributions. However, it may not perform well if the data violates the underlying assumptions, such as having heavy-tailed distributions or strong dependencies among features. In such cases, other classification algorithms that can handle continuous data more flexibly, such as Gaussian Mixture Models or Bayesian networks, may be more suitable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "5\n",
    "\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks or Probabilistic Graphical Models, are powerful models for representing and reasoning about uncertain knowledge using probability theory. They provide a graphical representation of dependencies among variables and capture the probabilistic relationships between them.\n",
    "\n",
    "A BBN consists of two main components: nodes and directed edges. The nodes represent variables or events, and the edges represent the probabilistic dependencies between them. Each node has an associated conditional probability table (CPT) that specifies the probabilities of the node given its parents in the network.\n",
    "\n",
    "The working principle of BBNs involves using Bayes' theorem and the network structure to perform probabilistic inference. Given observed evidence (values of some variables) in the network, BBNs can calculate the posterior probabilities of other variables. This inference process involves propagating the evidence through the network, updating the probabilities based on the observed data, and computing the posterior probabilities using Bayes' theorem.\n",
    "\n",
    "BBNs have a wide range of applications across various domains, including:\n",
    "\n",
    "Decision Support Systems: BBNs can model complex decision problems by incorporating uncertain factors and dependencies. They can assist in decision making by calculating the probabilities of different outcomes based on available evidence.\n",
    "\n",
    "Risk Analysis: BBNs are used to assess and analyze risks in various fields, such as finance, healthcare, and engineering. They can model the relationships between risk factors and evaluate the probabilities and impacts of different risk scenarios.\n",
    "\n",
    "Diagnosis and Medical Decision Making: BBNs can be used to model medical conditions and symptoms to aid in diagnosis. They can handle uncertain and incomplete information and provide probabilistic assessments of different diseases based on observed symptoms and test results.\n",
    "\n",
    "Environmental Modeling: BBNs are employed to model complex environmental systems and assess the impacts of various factors. They can analyze the relationships between environmental variables, such as pollution levels, weather patterns, and ecological changes.\n",
    "\n",
    "While BBNs are powerful tools for probabilistic modeling and inference, they may not be suitable for resolving all types of issues. Their effectiveness depends on the availability and quality of data, the accuracy of the model structure and parameters, and the complexity of the problem at hand. BBNs may face challenges in handling large-scale networks, dealing with highly interdependent variables, and incorporating time-dependent or dynamic systems. In such cases, alternative modeling approaches, such as dynamic Bayesian networks or Monte Carlo simulations, may be more appropriate.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To calculate the chances that an alarm would be triggered when an individual is actually an intruder, we can use Bayes' theorem.\n",
    "\n",
    "Let's denote:\n",
    "\n",
    "I = 1 as the event that an individual is an intruder.\n",
    "A = 1 as the event that an alarm is triggered.\n",
    "We are given the following probabilities:\n",
    "P(A = 1|I = 1) = 0.98 (the probability of an alarm when an individual is an intruder)\n",
    "P(A = 1|I = 0) = 0.001 (the probability of an alarm when an individual is not an intruder)\n",
    "P(I = 1) = 0.00001 (the likelihood of an intruder in the passenger population)\n",
    "\n",
    "We want to find P(I = 1|A = 1), the probability that an individual is actually an intruder given that an alarm is triggered.\n",
    "\n",
    "According to Bayes' theorem, we have:\n",
    "\n",
    "P(I = 1|A = 1) = (P(A = 1|I = 1) * P(I = 1)) / P(A = 1)\n",
    "\n",
    "To calculate P(A = 1), we can use the law of total probability:\n",
    "\n",
    "P(A = 1) = P(A = 1|I = 1) * P(I = 1) + P(A = 1|I = 0) * P(I = 0)\n",
    "\n",
    "Since P(I = 0) = 1 - P(I = 1), we can substitute this into the equation:\n",
    "\n",
    "P(A = 1) = P(A = 1|I = 1) * P(I = 1) + P(A = 1|I = 0) * (1 - P(I = 1))\n",
    "\n",
    "Now we can substitute the given values and calculate the probabilities:\n",
    "\n",
    "P(A = 1) = (0.98 * 0.00001) + (0.001 * (1 - 0.00001))\n",
    "\n",
    "Finally, we can substitute the calculated values back into Bayes' theorem to find P(I = 1|A = 1):\n",
    "\n",
    "P(I = 1|A = 1) = (P(A = 1|I = 1) * P(I = 1)) / P(A = 1)\n",
    "\n",
    "Note that the probability of an alarm being triggered when an individual is actually an intruder is influenced by both the probability of an alarm given an intruder and the likelihood of an intruder in the population.\n",
    "\n",
    "By calculating these probabilities, we can determine the chances that an alarm would be triggered when an individual is actually an intruder.\n",
    "To calculate the probability, let's substitute the given values into the equations:\n",
    "\n",
    "P(A = 1) = (0.98 * 0.00001) + (0.001 * (1 - 0.00001))\n",
    "P(I = 1|A = 1) = (P(A = 1|I = 1) * P(I = 1)) / P(A = 1)\n",
    "\n",
    "Let's calculate the probabilities using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a00bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an alarm being triggered when an individual is actually an intruder:\n",
      "0.009704988165856267\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_A_given_I1 = 0.98\n",
    "P_A_given_I0 = 0.001\n",
    "P_I1 = 0.00001\n",
    "\n",
    "# Calculate P(A = 1)\n",
    "P_A1 = (P_A_given_I1 * P_I1) + (P_A_given_I0 * (1 - P_I1))\n",
    "\n",
    "# Calculate P(I = 1|A = 1)\n",
    "P_I1_given_A1 = (P_A_given_I1 * P_I1) / P_A1\n",
    "\n",
    "# Print the result\n",
    "print(\"The probability of an alarm being triggered when an individual is actually an intruder:\")\n",
    "print(P_I1_given_A1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a881d",
   "metadata": {},
   "source": [
    "7\n",
    "To calculate the likelihood that a person who tests positive is actually immune, we can use Bayes' theorem. Let's denote the events as follows:\n",
    "\n",
    "D: Person is immune (desired event)\n",
    "T: Test result is positive\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(D) = 0.02 (2% of those screened are antibiotic-resistant)\n",
    "P(T|~D) = 0.01 (1% false positives)\n",
    "P(T|D) = 0.05 (5% false negatives)\n",
    "\n",
    "We want to calculate P(D|T), the probability that a person is immune given a positive test result.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "P(D|T) = (P(T|D) * P(D)) / P(T)\n",
    "\n",
    "To calculate P(T), we can use the law of total probability:\n",
    "\n",
    "P(T) = P(T|D) * P(D) + P(T|~D) * P(~D)\n",
    "\n",
    "where P(~D) = 1 - P(D).\n",
    "\n",
    "Let's calculate the probabilities using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589b0c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood that a person who tests positive is actually immune:\n",
      "0.09259259259259259\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_D = 0.02\n",
    "P_T_given_not_D = 0.01\n",
    "P_T_given_D = 0.05\n",
    "\n",
    "# Calculate P(T)\n",
    "P_not_D = 1 - P_D\n",
    "P_T = P_T_given_D * P_D + P_T_given_not_D * P_not_D\n",
    "\n",
    "# Calculate P(D|T)\n",
    "P_D_given_T = (P_T_given_D * P_D) / P_T\n",
    "\n",
    "# Print the result\n",
    "print(\"The likelihood that a person who tests positive is actually immune:\")\n",
    "print(P_D_given_T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f3c22",
   "metadata": {},
   "source": [
    "8\n",
    "8\n",
    "To calculate the likelihood that the student can solve the exam problem, we can use Bayes' theorem. Let's denote the events as follows:\n",
    "S: The student can solve the exam problem (desired event)\n",
    "A: The problem is of form A\n",
    "B: The problem is of form B\n",
    "C: The problem is of form C\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(A) = 0.30\n",
    "P(B) = 0.20\n",
    "P(C) = 0.50\n",
    "\n",
    "We also have the following conditional probabilities based on the student's preparation:\n",
    "P(S|A) = 9/10\n",
    "P(S|B) = 2/10\n",
    "P(S|C) = 6/10\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "P(S) = P(S|A) * P(A) + P(S|B) * P(B) + P(S|C) * P(C)\n",
    "\n",
    "Let's calculate the likelihood using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5cedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood that the student can solve the exam problem:\n",
      "0.6100000000000001\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_A = 0.30\n",
    "P_B = 0.20\n",
    "P_C = 0.50\n",
    "\n",
    "# Given conditional probabilities\n",
    "P_S_given_A = 9/10\n",
    "P_S_given_B = 2/10\n",
    "P_S_given_C = 6/10\n",
    "\n",
    "# Calculate P(S)\n",
    "P_S = P_S_given_A * P_A + P_S_given_B * P_B + P_S_given_C * P_C\n",
    "\n",
    "# Print the result\n",
    "print(\"The likelihood that the student can solve the exam problem:\")\n",
    "print(P_S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104cdad2",
   "metadata": {},
   "source": [
    "To calculate the likelihood that the problem was of form A given the student's solution, we can use Bayes' theorem again. Let's denote the events as follows:\n",
    "A: The problem is of form A (desired event)\n",
    "S: The student solved the problem\n",
    "\n",
    "We want to calculate P(A|S), the probability that the problem was of form A given the student's solution.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "P(A|S) = (P(S|A) * P(A)) / P(S)\n",
    "\n",
    "Let's calculate the likelihood using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68215e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood that the problem was of form A given the student's solution:\n",
      "0.44262295081967207\n"
     ]
    }
   ],
   "source": [
    "# Calculate P(A|S)\n",
    "P_A_given_S = (P_S_given_A * P_A) / P_S\n",
    "\n",
    "# Print the result\n",
    "print(\"The likelihood that the problem was of form A given the student's solution:\")\n",
    "print(P_A_given_S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d51419",
   "metadata": {},
   "source": [
    "9\n",
    "\n",
    "To calculate the number of customers coming into the bank on a daily basis (10 hours), we need to consider the number of 5-minute intervals in 10 hours and the probability of a customer arriving in each interval.\n",
    "There are 10 hours in a day, which is equivalent to 600 minutes. Since each interval is 5 minutes long, we can calculate the total number of intervals as 600 minutes divided by 5 minutes:\n",
    "\n",
    "Number of intervals = 600 minutes / 5 minutes = 120 intervals\n",
    "\n",
    "Given that there is a 5% chance of a customer arriving in each 5-minute interval, we can calculate the expected number of customers as follows:\n",
    "\n",
    "Expected number of customers = Probability of customer arrival * Number of intervals\n",
    "= 0.05 * 120\n",
    "= 6 customers\n",
    "\n",
    "Therefore, on a daily basis (10 hours), we can expect approximately 6 customers to come into the bank.\n",
    "\n",
    "To determine the number of fake photographs and missed photographs on a daily basis, we need to consider the probabilities of false detection and missed detection.\n",
    "Since we have already calculated that there are approximately 6 customers on a daily basis, the number of missed photographs (photographs taken when there is a customer) would be equal to the number of customers. So, there would be 6 missed photographs.\n",
    "\n",
    "The number of fake photographs (photographs taken when there is no customer) can be calculated by considering the probability of false detection. Given that there is a 10% chance of false detection in each 5-minute interval when there is no customer, we can calculate the expected number of fake photographs as follows:\n",
    "\n",
    "Expected number of fake photographs = Probability of false detection * Number of intervals\n",
    "= 0.10 * 120\n",
    "= 12 fake photographs\n",
    "\n",
    "Therefore, on a daily basis, there would be approximately 12 fake photographs and 6 missed photographs.\n",
    "\n",
    "The likelihood that there is a customer if there is a photograph can be calculated using Bayes' theorem. Let's denote the events as follows:\n",
    "C: There is a customer\n",
    "P: There is a photograph\n",
    "\n",
    "We want to calculate P(C|P), the probability that there is a customer given there is a photograph.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "P(C|P) = (P(P|C) * P(C)) / P(P)\n",
    "\n",
    "We are given the following probabilities:\n",
    "P(C) = 0.05 (probability of a customer arriving in each 5-minute interval)\n",
    "P(P|C) = 0.99 (probability of a photograph when there is a customer)\n",
    "P(P) = (P(P|C) * P(C)) + (P(P|~C) * P(~C))\n",
    "\n",
    "P(P|~C) represents the probability of a photograph when there is no customer, which is given as 0.10. P(~C) represents the probability of no customer, which is equal to 1 - P(C).\n",
    "\n",
    "Let's calculate the likelihood using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc75e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood that there is a customer given there is a photograph:\n",
      "0.34256055363321797\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_C = 0.05\n",
    "P_P_given_C = 0.99\n",
    "P_P_given_not_C = 0.10\n",
    "P_not_C = 1 - P_C\n",
    "\n",
    "# Calculate P(P)\n",
    "P_P = (P_P_given_C * P_C) + (P_P_given_not_C * P_not_C)\n",
    "\n",
    "# Calculate P(C|P)\n",
    "P_C_given_P = (P_P_given_C * P_C) / P_P\n",
    "\n",
    "# Print the result\n",
    "print(\"The likelihood that there is a customer given there is a photograph:\")\n",
    "print(P_C_given_P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afcac3",
   "metadata": {},
   "source": [
    "10\n",
    "To create the conditional probability table (CPT) for the node \"Won Toss\" in the Bayesian Belief Network (BBN) for the match winning prediction problem, we need to define the conditional probabilities based on the conditional independence assumptions of the Nave Bayes classifier.\n",
    "\n",
    "Let's assume we have the following variables in the BBN:\n",
    "\n",
    "Won Toss (WT): Indicates whether the team won the toss or not (0 for not won, 1 for won).\n",
    "Weather (W): Indicates the weather condition during the match (0 for rainy, 1 for sunny).\n",
    "Pitch Condition (P): Indicates the pitch condition (0 for dry, 1 for wet).\n",
    "Team Strength (TS): Indicates the team strength (0 for weak, 1 for strong).\n",
    "Match Outcome (MO): Indicates the match outcome (0 for loss, 1 for win).\n",
    "Based on the Nave Bayes classifier assumptions, the Won Toss variable is conditionally independent of Weather, Pitch Condition, and Team Strength given the Match Outcome.\n",
    "\n",
    "The conditional probability table for Won Toss can be defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25c9fe",
   "metadata": {},
   "source": [
    "| Match Outcome | Won Toss = 0 | Won Toss = 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| Match Outcome = 0  |   P(WT=0|MO=0)  |   P(WT=1|MO=0)  |\n",
    "| Match Outcome = 1  |   P(WT=0|MO=1)  |   P(WT=1|MO=1)  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436813ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7858ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Won Toss = 0  Won Toss = 1\n",
      "Match Outcome                            \n",
      "0                       0.5           0.5\n",
      "0                       0.5           0.5\n",
      "1                       0.5           0.5\n",
      "1                       0.5           0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the conditional probability table\n",
    "data = {'Match Outcome': [0, 0, 1, 1],\n",
    "        'Won Toss = 0': [0.5, 0.5, 0.5, 0.5],\n",
    "        'Won Toss = 1': [0.5, 0.5, 0.5, 0.5]}\n",
    "\n",
    "cpt = pd.DataFrame(data)\n",
    "\n",
    "# Set 'Match Outcome' as the index\n",
    "cpt.set_index('Match Outcome', inplace=True)\n",
    "\n",
    "# Display the conditional probability table\n",
    "print(cpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786c3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
