{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1494f55d",
   "metadata": {},
   "source": [
    "1. Define the Bayesian interpretation of probability.\n",
    "2. Define probability of a union of two events with equation.\n",
    "3. What is joint probability? What is its formula?\n",
    "4. What is chain rule of probability?\n",
    "5. What is conditional probability means? What is the formula of it?\n",
    "6. What are continuous random variables?\n",
    "7. What are Bernoulli distributions? What is the formula of it?\n",
    "8. What is binomial distribution? What is the formula?\n",
    "9. What is Poisson distribution? What is the formula?\n",
    "10. Define covariance.\n",
    "11. Define correlation\n",
    "12. Define sampling with replacement. Give example.\n",
    "13. What is sampling without replacement? Give example.\n",
    "14. What is hypothesis? Give example.\n",
    "\n",
    "\n",
    "1\n",
    "The Bayesian interpretation of probability is a framework for understanding probability as a measure of subjective belief or degree of certainty in the occurrence of an event. According to Bayesian probability, an individual assigns a probability value to an event based on their prior knowledge, experiences, and available evidence. As new evidence is obtained, the probability is updated using Bayes' theorem, which combines prior beliefs with the likelihood of the observed data to obtain a revised or posterior probability.\n",
    "\n",
    "2\n",
    "\n",
    "The probability of the union of two events A and B is defined by the equation:\n",
    "P(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n",
    "\n",
    "The equation accounts for the fact that if A and B have some overlap (i.e., they are not mutually exclusive), the probability of their union should not double count the shared region (A ∩ B). By subtracting the probability of the intersection, we avoid counting it twice\n",
    "\n",
    "\n",
    "3\n",
    "\n",
    "Joint probability refers to the probability of two or more events occurring together. It is denoted as P(A ∩ B), where A and B are two events. The joint probability measures the likelihood of the simultaneous occurrence of events A and B.\n",
    "\n",
    "The formula for joint probability depends on the nature of the events. For independent events, the joint probability is calculated as the product of the individual probabilities:\n",
    "P(A ∩ B) = P(A) * P(B)\n",
    "\n",
    "For dependent events, where the occurrence of one event affects the probability of the other, the joint probability is calculated based on conditional probabilities using Bayes' theorem or other relevant probability rules.\n",
    "\n",
    "\n",
    "4\n",
    "\n",
    "\n",
    "The chain rule of probability is a fundamental rule in probability theory that allows us to calculate the joint probability of multiple events by breaking it down into a series of conditional probabilities. The chain rule is derived from the definition of conditional probability.\n",
    "\n",
    "The chain rule states that for events A₁, A₂, A₃, ..., Aₙ:\n",
    "P(A₁ ∩ A₂ ∩ A₃ ∩ ... ∩ Aₙ) = P(A₁) * P(A₂ | A₁) * P(A₃ | A₁ ∩ A₂) * ... * P(Aₙ | A₁ ∩ A₂ ∩ ... ∩ Aₙ₋₁)\n",
    "\n",
    "In other words, the joint probability of n events can be calculated by multiplying the probability of the first event with the conditional probabilities of each subsequent event given the occurrence of the previous events. The chain rule allows us to break down complex joint probability calculations into a series of simpler conditional probabilities.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "5\n",
    "Conditional probability refers to the probability of an event A occurring given that another event B has already occurred. It measures the likelihood of event A under the condition or information provided by event B. Conditional probability is denoted as P(A|B), where \"|\" represents \"given\" or \"conditional on.\"\n",
    "\n",
    "The formula for conditional probability is:\n",
    "P(A|B) = P(A ∩ B) / P(B)\n",
    "\n",
    "This formula calculates the probability of A and B both occurring (the intersection of A and B) divided by the probability of event B. It allows us to update our probability assessment of event A based on the knowledge or occurrence of event B.\n",
    "\n",
    "\n",
    "6\n",
    "\n",
    "\n",
    "Continuous random variables are variables that can take any value within a specified range or interval. They have an infinite number of possible values and are usually associated with measurements or quantities that can take on any real number within a given range. Examples of continuous random variables include height, weight, temperature, time, and distance.\n",
    "\n",
    "Unlike discrete random variables, which can only take on specific values, continuous random variables are characterized by probability density functions (PDFs) rather than probability mass functions (PMFs). The probability of observing a specific value in a continuous distribution is typically zero, but the probability is defined over intervals or ranges of values.\n",
    "\n",
    "7\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that models a single binary outcome or an event that can have only two possible outcomes, typically labeled as success (usually denoted by 1) and failure (usually denoted by 0). The Bernoulli distribution is named after Swiss mathematician Jacob Bernoulli.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by the formula:\n",
    "P(X = x) = p^x * (1 - p)^(1-x)\n",
    "\n",
    "where X is a random variable representing the outcome (either 1 or 0), p is the probability of success, and (1-p) is the probability of failure.\n",
    "\n",
    "8\n",
    "\n",
    "The binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of independent Bernoulli trials. It is used when each trial has only two possible outcomes (success or failure) and the probability of success remains constant across all trials.\n",
    "\n",
    "The probability mass function (PMF) of the binomial distribution is given by the formula:\n",
    "P(X = k) = C(n, k) * p^k * (1 - p)^(n-k)\n",
    "\n",
    "where X is a random variable representing the number of successes, n is the number of trials, k is the number of successes, p is the probability of success in a single trial, and C(n, k) is the binomial coefficient, also known as \"n choose k,\" which represents the number of ways to choose k successes from n trials.\n",
    "\n",
    "9\n",
    "\n",
    "The Poisson distribution is a discrete probability distribution that models the number of events that occur in a fixed interval of time or space. It is commonly used to model rare events that occur independently and with a constant average rate over time or space. The Poisson distribution is named after French mathematician Siméon Denis Poisson.\n",
    "\n",
    "The probability mass function (PMF) of the Poisson distribution is given by the formula:\n",
    "P(X = k) = (e^(-λ) * λ^k) / k!\n",
    "\n",
    "where X is a random variable representing the number of events, λ (lambda) is the average rate of events occurring per interval, k is the number of events (0, 1, 2, ...), e is the base of the natural logarithm (~2.71828), and k! denotes the factorial of k.\n",
    "\n",
    "\n",
    "\n",
    "10\n",
    "\n",
    "\n",
    "Covariance is a measure that quantifies the extent to which two random variables change together. It measures the linear relationship between two variables and indicates the direction (positive or negative) and strength of their relationship. Covariance can be used to assess how changes in one variable are associated with changes in another variable.\n",
    "\n",
    "Mathematically, the covariance between two random variables X and Y is calculated as:\n",
    "Cov(X, Y) = E[(X - E[X])(Y - E[Y])]\n",
    "\n",
    "where Cov(X, Y) represents the covariance, E[X] and E[Y] denote the expected values (means) of X and Y, and (X - E[X]) and (Y - E[Y]) represent the deviations from their means.\n",
    "\n",
    "Covariance can take positive or negative values. A positive covariance indicates a direct (positive) relationship between the variables, meaning they tend to increase or decrease together. A negative covariance indicates an inverse (negative) relationship, where one variable tends to increase while the other decreases.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "11\n",
    "\n",
    "\n",
    "Correlation is a statistical measure that quantifies the strength and direction of the linear relationship between two variables. Unlike covariance, correlation is a standardized measure that ranges from -1 to 1, making it easier to interpret.\n",
    "The most commonly used correlation coefficient is the Pearson correlation coefficient, denoted as r. It is calculated as the covariance between two variables divided by the product of their standard deviations:\n",
    "\n",
    "r = Cov(X, Y) / (σ(X) * σ(Y))\n",
    "\n",
    "where Cov(X, Y) represents the covariance between X and Y, and σ(X) and σ(Y) represent the standard deviations of X and Y, respectively.\n",
    "\n",
    "The Pearson correlation coefficient ranges from -1 to 1. A correlation of +1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship between the variables. Positive correlations imply that as one variable increases, the other tends to increase, while negative correlations indicate that as one variable increases, the other tends to decrease.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "\n",
    "Sampling with replacement refers to a sampling method where each selected item or observation is returned to the population before the next selection is made. In other words, each time an item is chosen, it is replaced back into the population, and it is possible for the same item to be selected multiple times. This means that each selection is independent of previous selections.\n",
    "For example, consider a bag containing five colored balls: red, blue, green, yellow, and orange. If you randomly select a ball from the bag, record its color, put it back in the bag, and repeat this process several times, you are sampling with replacement. Each time you select a ball, it has an equal chance of being any of the five colors, regardless of previous selections.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "13\n",
    "\n",
    "Sampling without replacement refers to a sampling method where each selected item or observation is not returned to the population after it is chosen. Once an item is selected, it is removed from the population, and subsequent selections are made from the reduced population. This means that each selection is dependent on previous selections, as the available options decrease with each selection.\n",
    "For example, let's say you have a deck of playing cards, and you randomly draw a card from the deck and record its value (e.g., Ace, King, Queen, etc.). Without replacing the card back into the deck, you repeat this process multiple times. Each time you draw a card, the available options for the next draw decrease because the selected cards are not returned to the deck. This is an example of sampling without replacement.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "14\n",
    "\n",
    "\n",
    "In statistics and research, a hypothesis is a proposed explanation or statement that can be tested or investigated. It is a tentative claim or assertion about a population or phenomenon based on limited evidence or prior knowledge. Hypotheses are typically formulated to explain or predict a certain relationship, difference, effect, or outcome.\n",
    "For example, consider a study investigating the effects of a new drug on reducing blood pressure. The hypothesis could be stated as follows: \"The new drug treatment significantly reduces systolic blood pressure in patients with hypertension compared to a placebo.\" This hypothesis proposes a cause-and-effect relationship between the new drug treatment and the reduction in blood pressure. The study would aim to collect data and analyze it to either support or reject the hypothesis based on the evidence obtained.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
